---
title: Simulation Hypothesis consequences
snippet: >-
  TODO.
cover: 
date: 2024-09-15T15:00:00.000Z
---

# Consciousness
We all experience consciousness. it’s similar to an emotion, gives us the identity of a single individual rather than making ourselves perceived as a collection of cells. I like to think that it’s a behavior that emerges from experiencing our brain functioning.

Likely consciousness is just an arbitrary threshold we assign on an intelligence spectrum. We can make an analogy between simple beings and combinatorial circuits e.g. ants mostly react to the external environment, they are basically a small lookup table, given the current inputs from sensors they move in a deterministic way. More complex beings need to remember past experience and learn. Consciousness probably arises from this complex process that uses previously learned facts combined with the current observed state to produce a complex behavior as output. There was likely evolutionary pressure to develop this internal representation of the world e.g. primitive humans could track down prays for days without the need to have them in sight all the time, there were forecasting how the animal behaved and simulating the internal state of mind of their fellow hunters.

<TODO: kurknagtz video>

There are two steps I’ve learned to approach learning about an emergent behavior: firstly we need to understand what’s the medium of the interaction, secondly we need to understand how the complex behavior emerges from simple interactions inside the medium. In our case I believe we started understanding the medium: it’s circuits made of biological neurons firing together when a specific input is presented. I’m skeptical that we need much more esoteric physics than we have today to explain why neurons are firing, but we surely should keep researching in order to build more sophisticated models, likely given the scale we need to uncover a lot of quantum effects. The second step is much more interesting in my opinion. Potentially consciousness arises from a stupidly high number of wired together relatively simple biological neural circuits. I think it’s possible that one day we would simply discover that disrupting 100M neural connection you don’t experience consciousness anymore.

A a weak proof of my conjecture is given from the field of mechanistic interpretability. Let’s talk about how the field is uncovering the mechanism used by artificial neural networks to store facts. Given enough parameters (enough complexity) the networks exhibits an emergent reasoning behavior, it becomes capable of executing simple arithmetics and make simple deductions from facts it memorized rather than simply regurgitating text in the training set. In other words it has a simplified internal representation of the world.

<TODO: 3blue1brown video>

An interesting fact supporting my conjecture is that humans brains have two emispheres connected together. On a small number of humans that connection has been disrupted with a surgical procedure, effectively creating a human with two brains that need to coordinate together without directly sending neural signals to each other. A lot of experiments have been conducted on these split brain people, for example showing images to only one eye and ask the other emisphere in charge of speech to articulate what they are seeing. While perception is definitely split, consciousness doesn’t seem to be, the two separate emispheres somehow learn other ways of communicating and consciousness still emerges.

Now it’s a very legit question to ask: what will happen if we go in the opposite direction? What happens when neurons firing in one person brain influence neurons in another person brain? What’s the minimum bandwidth (how many connected neurons) that causes a shared consciousness to emerge rather than two distinct ones? I recommend this interesting 8 hours Neuralink immersion.

<TODO: neuralink podcast>

- Consciousness arises from complexity and evolution pressure to maintain an internal state of the world
- sequential VS combinatorics logic
- Consciousness is a spectrum, being self-aware is just one of the steps. TODO Kurknagtz video
- Connecting two brain emispheres Creates a single contiousness, how many neuralink connections do you need for connecting two brain to experience a single consciousness?
- Poking at the brain: Neuralink interview

# What is simulation hypothesis
- Consciousness arises from complexity, dynamic system, Occam Razor
- Universe spawns other universes, if it can produce enough complexity
- Bare metal universe

# Parallel with video games
- Videogame and simulations we already make
- Assume videogame simulation for communicating to you. Probably concept of time and spacial dimensions can be wildly different between the simulated and above universe
- Interactions between simulated world and external one, moving around the world flips bits, can draw more power, can heat up the laptop, it definitely interacts
- Minimum amount of time and space to be simulated to make sense: plank distance and uncertainty principle. Videogame analogy breaks, but in principle we have minimum distances to discretely simulate.
- TODO: geohotz video

# What’s enough to feel consciousness?
- What’s needed for consciousness to arise? Necessary to move electrons and other physical pieces around?
- How much do you need to store? Do you need to store only the current state or can you store the entire universe from beginning at a minimum resolution?
- Block universe: TODO video
- Is the connection with bare metal universe necessary?

# Thought experiment
- Thought experiment: assume you can store block universe at a specific minimum but finite resolution. Above a threshold experience consciousness. Do you need to store all of it? Can it really be destroyed from the POV of the agents inside the universe or since it has been described once for them it exists forever? Does it even need to be described or the fact that a block universe could exists, than it make it exists from the POV of the agents. Do all possible universes exists and all possibly conscious agents experience the one where they are conscious?