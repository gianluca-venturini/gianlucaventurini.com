---
title: Simulation Hypothesis consequences
snippet: >-
  TODO.
cover: 
date: 2024-09-25T15:00:00.000Z
---

# What’s consciousness?
<!-- intro --> 
Everyone experiences consciousness. It gives us a sense of individual identity, rather than making us see ourselves as just a collection of cells. Consciousness might be the feeling we have while our brain is functioning.

<!-- definition of consciousness -->
Consciousness is a set of intellectual skills like awareness of surroundings, self-awareness, and displaying emotions. Not every being needs consciousness to survive and reproduce. Simple beings' behavior mostly depends on current inputs rather than internal state. For example, ants primarily react to their external environment. Factors such as light, pheromones from other ants, and the presence of food are the major factors kept into account for selecting the next actions. Their internal state still exists, but stores very little information e.g. some bacteria use chemical gradients, multicellular beings can use hormones. More complex beings, such as predators, need to learn from experiences, maintain complex internal states in their minds, react based on emotions, and engage in complex problem-solving.

In the next section we will explore how consciousness could emerge from a dynamic system with a very large number of components.

# Consciousness as emergent behavior
 
<!-- consciousness arises from complexity -->
Consciousness potentially arises in the brain from a process that combines learnings from the past, problem-solving skills with recent observations and current sensory inputs to produce sophisticated behavior. There likely was evolutionary pressure to learn to simulate the world in our minds. For example, primitive humans could track prey for days without needing to see them constantly. They collected subtle clues from the environment, forecasted the animal's behavior and were aware of the mental states of their fellow hunters before deciding the next action. They progressed from just choosing an action based on what they see right now, to choosing an action based on what they have learned that is itself based on a generalized aggregated experiences.

<TODO: kurknagtz video>

<!-- emergent behavior understanding -->
Can consciousness, particularly self-awareness, be explained as a behavior emerging from a sufficiently complex dynamic system? Can consciousness be simulated? Is it even possible to distinguish a truly self-aware system from one that just imitates it, e.g. an LLM that provides a similar human output.

Those are very tough philosophical questions. I won’t attempt to answer them.


# Single individual consciousness
<!-- perceive as one when being two -->
An interesting fact is how a human perceives themselve as one despite having brains with two distinct hemispheres connected together. These systems can operate so in synchrony that the feeling of a single “self” can arise.

Some humans have the hemispheres connection disrupted with a surgical procedure or traumatic event. They effectively have two distinct brains that need to coordinate without directly sending signals to each other. A lot of experiments have been conducted on these split brain people. For example showing images to only one eye and ask the other hemisphere in charge of speech to articulate what they are seeing. While perception is definitely split, consciousness doesn’t seem to be. The two separate hemispheres somehow learn other ways of communicating and a single consciousness still emerges.

Next let’s ask what’s necessary for multiple individuals to share the same consciousness.

# Multi-individual consciousness
<!-- how multiple humans can perceive as one? -->
Now the next question to ask: can a multi-person consciousness emerge if people are interacting together? What’s the minimum bandwidth necessary?

In the past three decades Internet facilitated the connection serving as medium, we’ve now more people connected at near speed of light than anytime in history. Unfortunately the bandwidth seems to be relatively small and very comparable to people talking together, we still type on keyboards, talk or read text. This is about to change in the next few years.

What happens when neurons firing in one person brain influence neurons in another person brain? It’s very exiting that Brain Computer Interfaces (BCIs) are now a reality. For example Neuralink has a tech stack that works in humans. BCIs technology has a lot of momentum, funding and media attention. Now that the science works it’s becomes an engineering problem. The increase in bandwidth is a very similar problem to miniaturized and exponentially scaling the transistor based integrated circuits, so my expectation is that we will soon have more communication bandwidth that we ever had between individuals.

I’m particularly exited about BCIs because is for the first time allowing us to read and write signals from individual neurons, allowing us to probe the brain at a sufficient low level that we may be able to start answering some of our questions that until now have been studied in philosophy or during tragic accidents where people loose certain brain functionality.

I recommend this interesting 8 hours Neuralink immersion with different people involved in the project.

<TODO: neuralink podcast>

In the next section I want to step back from philosophical questions and compare complex biological brains with artificial neural networks.

# Simulated consciousness

<!-- dynamic system assumption -->
Artificial neural networks (ANNs) are vaguely resembling the biological neural circuits of the brain. They simulate the firing of biological neurons when certain inputs are provided. A large amount of research is been conducted in the field of ANNs on them making them a good candidate for a model where consciousness could arise. I will make the far-fetched hypothesis that for consciousness to arise, is more important to have the right architecture with the right connection rather than accurately modeling all the interactions of the biological systems. Will a sufficiently complex ANN with the right architecture really start feeling self-awareness the way humans do? I know this conjecture feels a little far-fetched and unjustified with the tools we have today, but it’s useful for a series of analogies, so bare with me.

<!-- analogy with mechanistic interpretability -->
In the last few weeks I’ve been learning the field of mechanistic interpretability of artificial neural networks. It's interesting to see how exponentially more facts can be stored in the network compared to the number of parameters. Loosely speaking number parameters in a ANN is a proxy for number of neurons. Given the right architecture e.g. transformer architecture and enough parameters (enough complexity) the network exhibits emergent reasoning behavior. The network becomes for example capable of simple arithmetic or make simple deductions from facts it memorized rather than simply regurgitating text in the training set. In other words it has a compressed internal representation of the world. Now that we’ve seen how reasoning and fact storage are very similar in brains and ANN, let’s see the differences and where the current ANN architectures fall short in simulating consciousness.

<TODO: 3blue1brown video on storing facts>

<!-- what’s missing -->
Most of the complex ANNs are decoupled from the environment. The training step is done once and then the weights remain fixed for the whole functioning of the network. The networks don’t have the opportunity to keep probing the environment and somehow discover the boundary between what’s “self” and what’s environment. I believe this tight feedback loop is necessary to achieve self awareness. There are some experiments where agents interact with a simulated environment, I’m extremely curious to discover what emerging properties we will see there while using more complex architectures.

Another arguably even more important missing element is the drive to survive. If self-awareness arise from evolutionary pressure of self-preservation, removing it signals the network during the training that resources dedicated to self-preservation could be allocated to something else. Following this reasoning line, self-awareness is a building block of self-preservation. Without demanding the latter to emerge in the loss function we may have hard time to create the former.

<TODO: simulated agents video>

- Consciousness arises from complexity and evolution pressure to maintain an internal state of the world
- sequential VS combinatorics logic
- Consciousness is a spectrum, being self-aware is just one of the steps. TODO Kurknagtz video
- Connecting two brain emispheres Creates a single contiousness, how many neuralink connections do you need for connecting two brain to experience a single consciousness?
- Poking at the brain: Neuralink interview

# What is simulation hypothesis
The Simulation Hypothesis (SH) states that conscious beings could emerge inside a simulation of the universe. For the being inside the simulation the simulated reality is indistinguishable from the reality. Nick Bostrom, a strong supporter of the theory, suggests as argument that either humans won’t ever be able to simulate an universe with conscious beings, or if we will be capable, we already live in a simulation. The current exponential progress in computational power suggests the latter.

If we assume that consciousness can arise from a complex system, any actor capable of creating a simulation that allows such a degree of complexity may create conscious beings.

Something that always bothered me about the SH is the implicit hierarchy between universes. It relies on the existence of a original universe, a sort of “bare metal” that runs on top of “real physics” (analogy between bare metal VS virtual machine computation paradigms). SI doesn’t intellectually satisfies me, it feels incomplete, somewhat doesn’t pass the Occam’s Razor test, just adds extra simulation steps between the original universe creation and my experience of the world without attempting to explain the emergence of the original universe. An attempt to solve is the Mathematical Universe Hypothesis (MUH) that states that physics is not merely described by mathematics. According to MUH the existence of a mathematical description, implies the emergence of the physics.

- Consciousness arises from complexity, dynamic system, Occam Razor
- Universe spawns other universes, if it can produce enough complexity
- Bare metal universe

# Parallel with video games

MUH always seemed a little too abstract and seemingly non-falsifiable. In contrast SI seems much more testable because it assumes finite computation resources dedicated to our universe simulation. For example we could concentrate high level of information (energy or matter) in a small amount of space and see how the underline simulation behaves. We already observe weak evidences of the simulation running on finite resources, e.g. spacetime behaves weirdly in presence of high level of information, forming black holes, or at a very small scale not allowing us to measure precisely where a particle is located, forcing us to use probabilistic theories.

<TODO: geohot talk>

- Videogame and simulations we already make
- Assume videogame simulation for communicating to you. Probably concept of time and spacial dimensions can be wildly different between the simulated and above universe
- Interactions between simulated world and external one, moving around the world flips bits, can draw more power, can heat up the laptop, it definitely interacts
- Minimum amount of time and space to be simulated to make sense: plank distance and uncertainty principle. Videogame analogy breaks, but in principle we have minimum distances to discretely simulate.
- TODO: geohotz video

# What’s enough to feel consciousness?
- What’s needed for consciousness to arise? Necessary to move electrons and other physical pieces around?
- How much do you need to store? Do you need to store only the current state or can you store the entire universe from beginning at a minimum resolution?
- Block universe: TODO video
- Is the connection with bare metal universe necessary?

# In favor of MUH
- Thought experiment: assume you can store block universe at a specific minimum but finite resolution. Above a threshold experience consciousness. Do you need to store all of it? Can it really be destroyed from the POV of the agents inside the universe or since it has been described once for them it exists forever? Does it even need to be described or the fact that a block universe could exists, than it make it exists from the POV of the agents. Do all possible universes exists and all possibly conscious agents experience the one where they are conscious?
