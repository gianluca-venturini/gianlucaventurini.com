---
title: Simulation Hypothesis consequences
snippet: >-
  TODO.
cover: 
date: 2024-09-25T15:00:00.000Z
---

# Consciousness
<!-- intro --> 
Everyone experiences consciousness. It gives us a sense of individual identity, rather than making us see ourselves as just a collection of cells. Consciousness might be the feeling we have while our brain is functioning.

<!-- definition of consciousness -->
Consciousness is a set of intellectual skills like awareness of surroundings, self-awareness, and displaying emotions. Not every being needs consciousness to survive and reproduce. Simple beings' behavior mostly depends on current inputs rather than internal state. For example, ants primarily react to their external environment. Factors such as light, pheromones from other ants, and the presence of food are the major factors kept into account for selecting the next actions. Their internal state still exists, but stores very little information e.g. some bacteria use chemical gradients, multicellular beings can use hormones. More complex beings, such as predators, need to learn from experiences, maintain complex internal states in their minds, react based on emotions, and engage in complex problem-solving.

In the next section we will explore how consciousness could emerge from a dynamic system with a very large number of components.

# Consciousness as emergent behavior
 
<!-- consciousness arises from complexity -->
Consciousness potentially arises in the brain from a process that combines learnings from the past, problem-solving skills with recent observations and current sensory inputs to produce sophisticated behavior. There likely was evolutionary pressure to learn to simulate the world in our minds. For example, primitive humans could track prey for days without needing to see them constantly. They collected subtle clues from the environment, forecasted the animal's behavior and were aware of the mental states of their fellow hunters before deciding the next action. They progressed from just choosing an action based on what they see right now, to choosing an action based on what they have learned that is itself based on a generalized aggregated experiences.

<TODO: kurknagtz video>

<!-- emergent behavior understanding -->
Can consciousness, particularly self-awareness, be explained as a behavior emerging from a sufficiently complex dynamic system? Can consciousness be simulated? Is it even possible to distinguish a truly self-aware system from one that just imitates it, e.g. an LLM that provides a similar human output.

Those are very tough philosophical questions. I won’t attempt to answer them. In the next section I will compare a complex brain with artificial neural networks.

<!-- dynamic system assumption -->
Artificial neural networks are vaguely resembling the biological neural circuits of the brain. They are mostly modeling the firing of neurons when certain inputs are provided. A large amount of researchers is working on them experimenting with new architectures. I will make the far-fetched hypothesis that for consciousness to arise, is more important to have the right architecture with the right connection rather than accurately modeling all the little interactions of the biological systems.


To model the brain as a dynamic system we firstly need to understand what’s the medium of the interaction, secondly we need to understand how the complex behavior emerges from simple interactions inside the medium. In an oversimplified way: the medium is circuits made of biological neural tissue firing under certain conditions. For our thought experiment we assume we can vastly simplify it and use artificial neural networks



For our thought experiment is sufficient to assume that a model can be built and we can we can hypothesize that a model can be built, let’s not worry too much about details here and assume we can build a model and run simulations on it. Let’s focus on the second step that is much more interesting in my opinion. Given the simplified neural network model, consciousness could arise from the specific architecture used.

The hypothesis here is that it’s sufficient for neurons to be wired in a specific way for the system to experience consciousness. I acknowledge that it’s quite speculative to reduce consciousness to an emergent behavior of an oversimplified system and to expect to be able to simulate it. Will the simulation of the sufficiently complex neural network with the right architecture really start feeling self-awareness the way humans do? I know it feels a little far-fetched, but it’s useful for a series of analogies, so for now let’s call it a conjecture and see where it brings us.

<!-- analogy with mechanistic interpretability -->
In the last few weeks I’ve been fascinated by the field of mechanistic interpretability of artificial neural networks. It's interesting that exponentially more facts can be learned and stored in network parameters compared to the number of neurons. Parameter in this context is a threshold that tells us if a ”simulated neuron” downstream is firing when a connected upstream neuron fires and with what intensity. Given enough parameters (enough complexity) the networks exhibits an emergent reasoning behavior. The network becomes for example capable of executing simple arithmetics or make simple deductions from facts it memorized rather than simply regurgitating text in the training set. In other words it has a simplified internal representation of the world and it can retrieve it given a certain input.

<TODO: 3blue1brown video on storing facts>

<!-- what’s missing -->
- Artificial nets don’t explain finding purpose
- Feedback loops
- Not coupled enough with environment
- No drive to stay alive wired in the network, no goal
- Consciousness can’t arise because of that

# Single individual consciousness
- perceive as one when being two
Another interesting fact somewhat related to the conjecture is that a human perceives themselve as one despite having brains with two emispheres connected together. Two distinct systems can operate so in synchrony that the feeling of a single “self” can arise. A small number of humans have the emispheres connection disrupted with a surgical procedure or traumatic event. They effectively have two distinct brains that need to coordinate without directly sending neural signals to each other. A lot of experiments have been conducted on these split brain people, for example showing images to only one eye and ask the other emisphere in charge of speech to articulate what they are seeing. While perception is definitely split, consciousness doesn’t seem to be. The two separate emispheres somehow learn other ways of communicating and consciousness still emerges.


# Multi-individual consciousness

- how multiple humans can perceive as one?
Now the next question to ask: can a multi-person consciousness emerge if multiple people are interacting together? What’s the minimum bandwidth necessary? In the past three decades Internet facilitated the connection serving as medium, but the bandwidth seems to be relatively small and very comparable to people talking together. This is about to change in the next few years. What happens when neurons firing in one person brain influence neurons in another person brain? The very exciting part here is that BCIs like Neuralink are now a reality. The company has proven that the entire stack works in multiple humans and the technology has a lot of momentum in term of funding and media attention. Now that the science work it becomes an engineering problem. The increase in bandwidth is a very similar problem to miniaturized and exponentially scaling the transistor based Integrated circuits.

I recommend this interesting 8 hours Neuralink immersion.

<TODO: neuralink podcast>

- Consciousness arises from complexity and evolution pressure to maintain an internal state of the world
- sequential VS combinatorics logic
- Consciousness is a spectrum, being self-aware is just one of the steps. TODO Kurknagtz video
- Connecting two brain emispheres Creates a single contiousness, how many neuralink connections do you need for connecting two brain to experience a single consciousness?
- Poking at the brain: Neuralink interview

# What is simulation hypothesis
The Simulation Hypothesis (SH) states that conscious beings could emerge inside a simulation of the universe. For the being inside the simulation the simulated reality is indistinguishable from the reality. Nick Bostrom, a strong supporter of the theory, suggests as argument that either humans won’t ever be able to simulate an universe with conscious beings, or if we will be capable, we already live in a simulation. The current exponential progress in computational power suggests the latter.

If we assume that consciousness can arise from a complex system, any actor capable of creating a simulation that allows such a degree of complexity may create conscious beings.

Something that always bothered me about the SH is the implicit hierarchy between universes. It relies on the existence of a original universe, a sort of “bare metal” that runs on top of “real physics” (analogy between bare metal VS virtual machine computation paradigms). SI doesn’t intellectually satisfies me, it feels incomplete, somewhat doesn’t pass the Occam’s Razor test, just adds extra simulation steps between the original universe creation and my experience of the world without attempting to explain the emergence of the original universe. An attempt to solve is the Mathematical Universe Hypothesis (MUH) that states that physics is not merely described by mathematics. According to MUH the existence of a mathematical description, implies the emergence of the physics.

- Consciousness arises from complexity, dynamic system, Occam Razor
- Universe spawns other universes, if it can produce enough complexity
- Bare metal universe

# Parallel with video games

MUH always seemed a little too abstract and seemingly non-falsifiable. In contrast SI seems much more testable because it assumes finite computation resources dedicated to our universe simulation. For example we could concentrate high level of information (energy or matter) in a small amount of space and see how the underline simulation behaves. We already observe weak evidences of the simulation running on finite resources, e.g. spacetime behaves weirdly in presence of high level of information, forming black holes, or at a very small scale not allowing us to measure precisely where a particle is located, forcing us to use probabilistic theories.

<TODO: geohot talk>

- Videogame and simulations we already make
- Assume videogame simulation for communicating to you. Probably concept of time and spacial dimensions can be wildly different between the simulated and above universe
- Interactions between simulated world and external one, moving around the world flips bits, can draw more power, can heat up the laptop, it definitely interacts
- Minimum amount of time and space to be simulated to make sense: plank distance and uncertainty principle. Videogame analogy breaks, but in principle we have minimum distances to discretely simulate.
- TODO: geohotz video

# What’s enough to feel consciousness?
- What’s needed for consciousness to arise? Necessary to move electrons and other physical pieces around?
- How much do you need to store? Do you need to store only the current state or can you store the entire universe from beginning at a minimum resolution?
- Block universe: TODO video
- Is the connection with bare metal universe necessary?

# In favor of MUH
- Thought experiment: assume you can store block universe at a specific minimum but finite resolution. Above a threshold experience consciousness. Do you need to store all of it? Can it really be destroyed from the POV of the agents inside the universe or since it has been described once for them it exists forever? Does it even need to be described or the fact that a block universe could exists, than it make it exists from the POV of the agents. Do all possible universes exists and all possibly conscious agents experience the one where they are conscious?
