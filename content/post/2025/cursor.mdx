---
title: TODO
snippet: TODO
cover: /uploads/blog-subscribe/blog-subscribe-cover.webp
date: 2025-02-02T15:00:00.000Z
---
<intro>

# Developing complex systems with LLM Copilots
In the past year I've spent some time integrating LLMs in coding tasks and I wanted to share few thoughts. Whenever I'm working on a coding task, I try to find simple sections I can delegate to the model and then review.

Initially, about one year ago, my main use-case was speeding up typing speed of very easy code I exactly how to write myself. Let the model write something somewhat good really fast and then refine it manually adding few tests. I haven't noticed a significant practical difference between different models like Claude Sonnet 3.5 and GPT4o for this use-case.

Lately when models could lookup web pages I started using much more the chat function to discuss various ideas and let the model come up with examples and simple implementations. What enabled this use-case are tools that provide context about the current code selection and semantically related files. Reasoning models like o1 or o3 help me understand the tradeoff between different approaches and often point out something I could learn. In the next section I'll talk about how to effectively learn.

## Great for learning
When learning a new language or framework it's very useful to ask a lot of questions. I frequently ask for the best pattern to solve a problem in a new language or framework. For example, I recently wrote a Raft implementation in Rust and I was able to learn asynchronous patterns, concurrency primitives and futures. I just wrote the code and let the model refine it until it compiles and passes the tests, asking a lot of questions along the way.

Learning by doing assisted by an infinitely patient LLMs works really well for me. Learning a new pattern while I need it for solving a problem is way more effective than reading an entire blog about it or documentation. I often write a half-baked idea and have the model tell me how the average developer would do it in that specific language. E.g. how to spin up a series of threads and send parallel network requests. The inline code completion constantly suggests what framework API I should use, and it should be lightning fast to be useful for real tasks.

## Bad at strongly opinionated tasks
I find LLM pretty bad at holding strong opinions or pushing back on bad questions. When I'm exploring new problems or libraries I need to learn the terminology in order to ask detailed questions. Models are often answering to the specific question, sometimes even hallucinating a reasonable API that doesn't exists. I would rather prefer the model to correct some of the wrong assumptions I've made while asking the question and teach me something.

<example generic question with too specific answer>

I suspect being condescending is intentionally baked-in during the final fine-tuning phase of the model training, for general tasks nobody likes a pedantic professor that keeps correcting. I don't appreciate this trait because when building a complex system it's very important to get details right: invariants, edge cases, understanding all the user flows etc.

LLM are particularly bad at designing new architectures. For example while researching and prototyping modern solutions for frontend state management it's easy to have the model list all the libraries and write simple examples. It is much harder to let it integrate them in a simple module that contains with custom patterns in a legacy code-base. It seems to be lacking intuition about what a senior developer would do in that task, no matter how in details I explain it.

## Bad for intellectual stimulation
I think LLMs lower the intellectual stimulation of solving a problem. I'm sometimes finding myself delegating tasks that are mildly uncomfortable, like writing a complex boolean condition or calculating the index of the element of an array. This happens because many of the tools I'm using are auto-completing code for me by default.

Removing these small but frequent intellectual mini-puzzles decreases the satisfaction of a coding task, making it almost a chore, a box to check. The other more subtle issue is the wrong implementation, and since I didn't feel like writing it, I probably don't feel like thinking too hard about it either. It regularly misses corner cases and commits for example off-by-1 errors.

Having complex parts of the code written by the model and only half-checked is basically introducing black box code and I believe it's a serious concern in now day software development. There are a few mitigations. Firstly we could pay very close attention to what the model spits out and potentially rewrite the most complex or confusing parts. Additionally, we can manually write very comprehensive tests.

Let's now talk about a couple of tools I'm using: Github CoPilot and Cursor. Note that these tools are improving really fast and likely the next section will be outdated soon.

# Github CoPilot
It is a VSCode extension. I find it a little clunky to use: it's pretty slow in generating code, especially if the module is large. It requires to add all the files we want to edit manually and doesn't have good discovering capabilities. The model selection is also a little limited, but as mentioned before I don't notice a huge difference between them, so not a deal breaker.

I think it's a good initial step into LLM-collaboration code because it has the basic features of chat and compose code in a small amount of files.

<example find redis client>

# Cursor Editor
The Cursor team decided for a different approach: they forked VSCode and built many features that are not available simply writing an extension. 

## What I like
Discovering through RAG what files are relevant to the change I'm making or discussing is very useful. Specifically I find useful that it looks up the interface of a function while I'm trying to invoke it and pass the local variables doing some light data massaging if needed.

I also like the ability of looking up documentation online and provide public API suggestions with references, I want to learn how to leverage this even more.

I really like the micro interactions and quality of life improvements. I use a lot the CMD+K and TAB-to-complete. I also keeps in memory the last few lines of code I wrote, so while I'm jumping around files the completions are relevant with the task I'm executing on e.g. it suggests to call the function that I just wrote in another module.


## What I don't like
I don't like the idea that it could one day diverge from VSCode. Philosophically the editor is such a fundamental part of my dev workflow: I spend a lot of time customizing settings and building muscle memory around keyboard shortcuts. The reason I even considered switching to Cursor is that is fully compatible with VSCode, all my extension just work perfectly.

I noticed few UI small annoyances: there was a bug with the autocompletion window being stuck on the top and not being able to move it. Since it's only sporadically rebased on top of VSCode, means it doesn't contain the latest features. At the moment of writing Cursor is using 1.93.1 from last August, while version 1.96.4 is available, so it's roughtly 5 months behind and may have impact on certain extensions in case they require the latest VSCode features.

Lastly I tried the agent mode on a pet project: I wanted to remove the unnecessary exports in a Typescript project using ts-prune and having the agent edit few files at a time. I wasn't able to keep it focused on the task, it only waits ~10s of command running before killing the terminal and when it make edits it renames modules and functions instead of just removing the `export` word. I find it quite unreliable for now, but I'm sure it's going to improve fast.

# Opportunities: what I think will improve soon
- Condescending, need more push back <video for sister Anthropic CEO>, reasoning models O1, O3 push back more
- Code generation speed
- Ecosystem: Rust error correction better than typescript because of compiler. Compiler and language server could return much reacher context 
- Editor could become a commodity once the developer community converges on a set of features, nothing in Cursor seems crazy difficult to build, they just got there fast
- Agent

Conclusions
- Code autocompletion and low intellectual stimulation BAD