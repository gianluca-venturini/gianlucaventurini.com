---
title: Thoughts on consciousness
snippet: >-
  TODO.
cover: 
date: 2024-10-15T15:00:00.000Z
---

# What’s consciousness?
<Comment comment="definition of consciousness" />
Everyone experiences consciousness. Self-consciousness gives us a sense of individual identity, rather than making us perceive ourselves as a mere collection of cells. Access consciousness makes us access information for reasoning. Phenomenal consciousness is a subjective sensory experience, emotion and thoughts.

Not every being needs consciousness to survive and reproduce. For example, ants primarily react to their external environment, they reproduce fast and, if they survive long enough, store learned information in their genetic code. Their internal state still exists, but stores very little information e.g. some bacteria use chemical gradients, multicellular beings can use hormones. More complex beings, that reproduce much more slowly and have fewer offsprings, need to learn from experiences, maintain complex internal states in their minds, react based on emotions, and engage in complex problem-solving.

Self-consciousness is particularly intriguing. It’s experiencing our brain functioning while reasoning about itself.

In the next section we will explore how consciousness could emerge from a complex dynamic system with a very large number of feedback loops.

# Consciousness as emergent behavior
 
<Comment comment="consciousness arises from complexity" />
Consciousness potentially arises in the brain from a process that combines learnings from the past, problem-solving skills with recent observations and current sensory inputs to produce sophisticated behavior. There likely was evolutionary pressure to learn to simulate the world in our minds. For example, primitive humans could track prey for days without needing to see them constantly. They collected subtle clues from the environment, forecasted the animal's behavior based on learnings or stories from others and guess the mental states of their fellow hunters. We progressed from just choosing an action based on what they saw, to very complex reasoning based on generalized previous experiences.

<VideoYoutube id="H6u0VBqNBQ8" />

<Comment comment="questions" />
Can consciousness, particularly self-consciousness, be explained as a behavior emerging from a sufficiently complex dynamic system? Can consciousness be simulated? Is it even possible to distinguish a truly self-aware system from one that just imitates it, e.g. an advanced LLM that provides text output without any subjective experience.

Those are very large philosophical questions. We’re nowhere near answering them, especially because we don’t even have a precise definition of what it means to be conscious, let alone being able to test it. What we can do is reasoning and making educated guesses. Let’s start looking at the implications of a single consciousness arising from two brains.

# Single individual consciousness
<Comment comment="perceive as one while being two" />
An interesting fact is how a human perceives themselves as one despite having brains with two distinct hemispheres connected together. These systems can cooperate in synchrony that the feeling of a single “self” arises.

<Comment comment="sensory experience, illusion" />
Your brain wouldn’t even know it’s split in half. This gives us a clue: self-awareness could be related to our senses. Since we can’t sense we have two hemispheres, then we can’t experience two separate consciousness.

Some humans have the hemispheres connection disrupted because of a surgical procedure or a traumatic event. They effectively have two distinct brains that need to coordinate without directly sending signals to each other. Experiments have been conducted on these split brain people. For example showing images to only one eye and ask the other hemisphere in charge of speech to articulate what they are seeing. While perception is definitely split, consciousness doesn’t seem to be. The two separate hemispheres somehow learn other ways of communicating and a single consciousness still emerges.

Next let’s ask if it’s possible for multiple individuals to share the same self-consciousness.

# Multi-individual consciousness
<Comment comment="how multiple humans can perceive as one?" />
Can a multi-person consciousness emerge? Can the group experience a single self-consciousness? How should the brains be connected? What’s the bandwidth necessary in this connection?

In the past three decades Internet facilitated the connection serving as medium. We have now people connected at near speed of light. Unfortunately the bandwidth seems to be relatively small and limited by typing, reading, talking and listening and very comparable to offline communication, just at a larger scale and making distance irrelevant. The bandwidth is about to increase exponentially in the next few years. Some of these questions could be answered.

What happens when neurons firing in one person brain influence neurons in another person brain? It’s very exiting that Brain Computer Interfaces (BCIs) are now a reality. Neuralink have a prototype working in humans, demonstrating that the science works. BCIs technology has a lot of momentum, funding and media attention. BCIs communication bandwidth is now an engineering problem. I predict it will scale exponentially as seen in computation power in silicon-based transistors.

I’m particularly exited about BCIs because is for the first time allowing us to read and write signals from individual neurons. It allows us to probe the brain at the smallest meaningful resolution. The single neuron is our processing system “atom”. Maybe we not even need to understand the physics of it to explain consciousness. We now have the tool to move these questions from philosophy to a falsifiable hypothesis we can test.

I recommend this interesting 8 hours Neuralink immersion.

<VideoYoutube id="Kbk9BiPhm7o" />

In the next section I want to step back from philosophical questions and compare complex biological brains with artificial neural networks and see what they have in common.

# Simulated consciousness

<Comment comment="dynamic system assumption" />
Artificial neural networks (ANNs) are vaguely resembling biological neural circuits of the brain. A large amount of research is being conducted in the field. We are building exponentially more complex networks exploring many different ways of wiring them. They are the ideal candidate of a dynamic system where consciousness could arise. I will make the far-fetched hypothesis that for consciousness to arise, is more important to have the right architecture (the wirings of these neurons) rather than a super high fidelity simulation of the actual biological system.

Will a sufficiently complex ANN with the right architecture really start feeling self-awareness the way humans do?

<Comment comment="analogy with mechanistic interpretability" />
In the last few weeks I’ve been learning the field of mechanistic interpretability of artificial neural networks. It's interesting to see how exponentially more facts can be stored in the network compared to the number of parameters, thanks to Johnson Lindenstrauss lemma. Loosely speaking number parameters in an ANN is analogous to number of neurons. Given the right architecture (e.g. transformer architecture) and enough parameters (enough complexity) the network exhibits emergent reasoning behavior. The network becomes for example capable of simple arithmetic or deduce novel ideas from facts it memorized rather than simply regurgitating training set text. It has a compressed complex internal representation of the world and simple reasoning behavior now emerges. What other parts of consciousness can emerge? Now that we’ve seen how reasoning and fact storage are very similar in brains and ANN, let’s see the differences and where ANNs fall short in simulating consciousness.

<VideoYoutube id="9-Jl0dxWQs8" />

<Comment comment="what’s missing" />
Most of the complex ANNs are decoupled from the environment. The training step is done once and then the weights remain fixed for the whole functioning of the network. The networks don’t have the opportunity to keep probing the environment and somehow discover the boundary between what’s “self” and what’s environment. If it’s true that self-consciousness arises from sensory inputs, removing this tight feedback loop may disrupt it. There are some experiments where agents interact with a simulated environment. I’m extremely curious to discover the emerging properties of progressively more complex environment probing agents.

Another arguably even more important missing element is the drive to survive. If self-consciousness arise from evolutionary pressure of self-preservation, removing it signals the network during the training that resources dedicated to self-preservation could be allocated to something else. Following this reasoning line, self-preservation could be a building block of self-consciousness. Without demanding the latter to emerge in the objective function we may have hard time to create the former.

<VideoYoutube id="1kV-rZZw50Q" />
