---
title: Thoughts on consciousness
snippet: >-
  TODO.
cover: 
date: 2024-10-15T15:00:00.000Z
---

# What’s consciousness?
<Comment comment="definition of consciousness" />
Everyone experiences consciousness. Self-consciousness gives us a sense of individual identity, rather than making us perceive ourselves as a mere collection of cells. Access consciousness makes us access information for reasoning. Phenomenal consciousness is a subjective sensory experience, emotion and thoughts.

Not every being needs consciousness to survive and reproduce. For example, ants primarily react to their external environment, they reproduce fast and, if they survive long enough, store learned information in their genetic code. Their internal state still exists, but stores very little information e.g. some bacteria use chemical gradients, multicellular beings can use hormones. More complex beings, that reproduce much more slowly and have fewer offsprings, need to learn from experiences, maintain complex internal states in their minds, react based on emotions, and engage in complex problem-solving.

Self-consciousness is particularly intriguing. It’s experiencing our brain functioning while reasoning about itself.

In the next section we will explore how consciousness could emerge from a complex dynamic system with a very large number of feedback loops.

# Consciousness as emergent behavior
 
<Comment comment="consciousness arises from complexity" />
Consciousness potentially arises in the brain from a process that combines learnings from the past, problem-solving skills with recent observations and current sensory inputs to produce sophisticated behavior. There likely was evolutionary pressure to learn to simulate the world in our minds. For example, primitive humans could track prey for days without needing to see them constantly. They collected subtle clues from the environment, forecasted the animal's behavior based on learnings or stories from others and guess the mental states of their fellow hunters. We progressed from just choosing an action based on what we saw, to very complex reasoning based on generalized previous experiences.

<VideoYoutube id="H6u0VBqNBQ8" />

<Comment comment="questions" />
Can consciousness, particularly self-consciousness, be explained as a behavior emerging from a sufficiently complex dynamic system? Can consciousness be simulated? Is it even possible to distinguish a truly self-aware system from one that just fakes it (e.g. a Large Language Model)?

Those are very large philosophical questions. We’re nowhere near answering them, especially because we don’t even have a precise definition of what it means to be conscious, let alone being able to test it. What we can do is reasoning and making educated guesses. Next let’s explore how a single consciousness can arise from two brains.

# Single individual consciousness
<Comment comment="perceive as one while being two" />
It's facinating how humans perceive themselves as an individual despite having brains with two distinct hemispheres connected together. These dynamic systems cooperate so in synchrony that the feeling of a single “self” arises.

<Comment comment="sensory experience, illusion" />
Your brain doesn't even know it’s split in half. This gives us a clue: self-consciousness could be related to our senses. Since we can’t sense we have two distinct hemispheres, then we can’t experience two separate consciousnesses.

It remains true no matter how much we convince ourselves that intuitively the two hemispheres should work independently. It remains true even after they are phisically separated. Some humans have the connection disrupted because of a surgical procedure or a traumatic event. They effectively have two distinct brains that need to coordinate without directly sending signals to each other.

Experiments have been conducted on these split brain people. For example showing images to only one eye and ask the other hemisphere in charge of speech to articulate what they are seeing. While perception is definitely split, consciousness doesn’t seem to be. The two separate hemispheres somehow learn other ways of communicating and a single consciousness still emerges. A single consciousness emerges from two separate dynamic systems that function in close proximity.

Next let’s ask if it’s possible for multiple individuals to share the same self-consciousness.

# Multi-individual consciousness
<Comment comment="how multiple humans can perceive as one?" />
Can a multi-person consciousness emerge? Can the group experience a single self-consciousness? How should the brains be connected? What’s the minimum bandwidth necessary?

In the past three decades Internet served as a connection medium. We have now billions of people connected at near speed of light. Unfortunately the bandwidth seems to be relatively small and limited by typing, reading, talking and listening. It's very comparable to offline communication, just at a larger scale and making distance irrelevant.

Thanks to Brain Computer Interfaces (BCIs), the bandwidth is about to increase exponentially in the next few years. We are now at the point where we can start attacking these questions.

What happens when neurons firing in one person brain influence neurons in another person brain? Neuralink has demonstrated that can read individual neurons firing and has a working prototype in two humans. BCIs technology has a lot of momentum, funding and media attention. Increasing BCIs communication bandwidth is now an engineering problem. I predict it will scale exponentially as seen in computation power in silicon-based transistors.

I’m particularly exited about BCIs because for the first time we can read and write signals from individual neurons. It allows us to probe the brain at the smallest meaningful resolution: the single neuron, the brain “atom”. Maybe we do not even need to understand the physics of it to explain consciousness. We now have the tool to move these questions from philosophy to a falsifiable hypothesis we can test.

I recommend this interesting 8 hours Neuralink immersion.

<VideoYoutube id="Kbk9BiPhm7o" />

In the next section I want to step back from philosophical questions and compare complex biological brains with artificial neural networks and see what they have in common.

# Simulated consciousness

<Comment comment="dynamic system assumption" />
Artificial neural networks (ANNs) are vaguely resembling biological neural circuits of the brain. A large amount of research is being conducted in the field. We are building exponentially more complex networks exploring many different ways of wiring them. They are the ideal candidate of a dynamic system where consciousness could arise. I will make the far-fetched hypothesis that for consciousness to arise, is more important to have the right architecture (the wirings of these neurons) rather than a super high fidelity simulation of the actual biological system.

Will a sufficiently complex ANN with the right architecture really start feeling self-consciousness the way humans do?

<Comment comment="analogy with mechanistic interpretability" />
In the last few weeks I’ve been learning the field of mechanistic interpretability of artificial neural networks. It's interesting to see how exponentially more facts can be stored in the network compared to the number of parameters, thanks to Johnson Lindenstrauss lemma. Loosely speaking number parameters in an ANN is analogous to number of neurons. Given the right architecture (e.g. transformer architecture) and enough parameters (enough complexity) the network exhibits emergent reasoning behavior. The network becomes for example capable of simple arithmetic or deduce novel ideas from facts it memorized rather than simply regurgitating training set text. It has a compressed complex internal representation of the world and simple reasoning behavior now emerges. What other parts of consciousness can emerge?

<VideoYoutube id="9-Jl0dxWQs8" />

Now that we’ve seen how reasoning and fact storage are very similar in brains and ANN, let’s see the differences and where ANNs fall short in simulating consciousness.

<Comment comment="what’s missing" />
Most complex ANNs are decoupled from the environment. For example LLMs parameters remain fixed after the training phase. The ANN doesn't have the opportunity to keep probing the environment and discover the boundary between what’s “self” and what’s environment. If it’s true that self-consciousness arises from sensory inputs, removing this tight feedback loop may disrupt it. There are some experiments where agents interact with a simulated environment. I’m extremely curious to discover the emerging properties of progressively more complex environment probing agents.

Another arguably even more important missing element is the drive to survive. If self-consciousness arise from evolutionary pressure of self-preservation, removing it signals the network during the training that resources dedicated to self-preservation could be allocated to something else. Following this reasoning, self-preservation could be a building block of self-consciousness. Without demanding the latter to emerge in the objective function we may have hard time to create the former.

<VideoYoutube id="1kV-rZZw50Q" />
